

R version 3.5.2 (2018-12-20) -- "Eggshell Igloo"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ### Chapter 3: Data Pre-Processing
> ### Section 3.1 Case Study: Cell Segmentation in High-Content Screening
> 
> library(AppliedPredictiveModeling)
> data(segmentationOriginal)
> ## Retain the original training set
> segTrain <- subset(segmentationOriginal, Case == "Train")
> 
> ## Remove the first three columns (identifier columns)
> segTrainX <- segTrain[, -(1:3)]
> segTrainClass <- segTrain$Class
> ################################################################################
> ### Section 3.2 Data Transformations for Individual Predictors
> 
> ## The column VarIntenCh3 measures the standard deviation of the intensity
> ## of the pixels in the actin filaments
> 
> max(segTrainX$VarIntenCh3)/min(segTrainX$VarIntenCh3)
[1] 870.8872
> 
> library(e1071)
> skewness(segTrainX$VarIntenCh3)
[1] 2.391624
> 
> library(caret)
Loading required package: lattice
Loading required package: ggplot2
> ## Use caret's preProcess function to transform for skewness
> segPP <- preProcess(segTrainX, method = "BoxCox")
> 
> ## Apply the transformations
> segTrainTrans <- predict(segPP, segTrainX)
> ## Results for a single predictor
> segPP$bc$VarIntenCh3
Box-Cox Transformation

1009 data points used to estimate Lambda

Input data summary:
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
  0.8693  37.0615  68.1316 101.6718 124.9899 757.0210 

Largest/Smallest: 871 
Sample Skewness: 2.39 

Estimated Lambda: 0.1 
With fudge factor, Lambda = 0 will be used for transformations

> histogram(~segTrainX$VarIntenCh3,
+           xlab = "Natural Units",
+           type = "count")
> histogram(~log(segTrainX$VarIntenCh3),
+           xlab = "Log Units",
+           ylab = " ",
+           type = "count")
> segPP$bc$PerimCh1
Box-Cox Transformation

1009 data points used to estimate Lambda

Input data summary:
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  47.74   64.37   79.02   91.61  103.24  459.77 

Largest/Smallest: 9.63 
Sample Skewness: 2.59 

Estimated Lambda: -1.1 

> histogram(~segTrainX$PerimCh1,
+           xlab = "Natural Units",
+           type = "count")
> histogram(~segTrainTrans$PerimCh1,
+           xlab = "Transformed Data",
+           ylab = " ",
+           type = "count")
> ################################################################################
> ### Section 3.3 Data Transformations for Multiple Predictors
> 
> ## R's prcomp is used to conduct PCA
> pr <- prcomp(~ AvgIntenCh1 + EntropyIntenCh1, 
+              data = segTrainTrans, 
+              scale. = TRUE)
> transparentTheme(pchSize = .7, trans = .3)
> xyplot(AvgIntenCh1 ~ EntropyIntenCh1,
+        data = segTrainTrans,
+        groups = segTrain$Class,
+        xlab = "Channel 1 Fiber Width",
+        ylab = "Intensity Entropy Channel 1",
+        auto.key = list(columns = 2),
+        type = c("p", "g"),
+        main = "Original Data",
+        aspect = 1)
> xyplot(PC2 ~ PC1,
+        data = as.data.frame(pr$x),
+        groups = segTrain$Class,
+        xlab = "Principal Component #1",
+        ylab = "Principal Component #2",
+        main = "Transformed",
+        xlim = extendrange(pr$x),
+        ylim = extendrange(pr$x),
+        type = c("p", "g"),
+        aspect = 1)
> ## Apply PCA to the entire set of predictors.
> 
> ## There are a few predictors with only a single value, so we remove these first
> ## (since PCA uses variances, which would be zero)
> 
> isZV <- apply(segTrainX, 2, function(x) length(unique(x)) == 1)
> segTrainX <- segTrainX[, !isZV]
> segPP <- preProcess(segTrainX, c("BoxCox", "center", "scale"))
> segTrainTrans <- predict(segPP, segTrainX)
> segPCA <- prcomp(segTrainTrans, center = TRUE, scale. = TRUE)
> 
> ## Plot a scatterplot matrix of the first three components
> transparentTheme(pchSize = .8, trans = .3)
> panelRange <- extendrange(segPCA$x[, 1:3])
> splom(as.data.frame(segPCA$x[, 1:3]),
+       groups = segTrainClass,
+       type = c("p", "g"),
+       as.table = TRUE,
+       auto.key = list(columns = 2),
+       prepanel.limits = function(x) panelRange)
> ## To filter on correlations, we first get the correlation matrix for the 
> ## predictor set
> 
> segCorr <- cor(segTrainTrans)
> 
> library(corrplot)
corrplot 0.84 loaded
> corrplot(segCorr, order = "hclust", tl.cex = .35)
> ## caret's findCorrelation function is used to identify columns to remove.
> highCorr <- findCorrelation(segCorr, .75)
> ### Section 3.8 Computing (Creating Dummy Variables)
> 
> data(cars)
> type <- c("convertible", "coupe", "hatchback", "sedan", "wagon")
> cars$Type <- factor(apply(cars[, 14:18], 1, function(x) type[which(x == 1)]))
> 
> carSubset <- cars[sample(1:nrow(cars), 20), c(1, 2, 19)]
> head(carSubset)
       Price Mileage      Type
267 12146.19   10011 hatchback
549 25948.96     636     sedan
763 12257.16   21492     sedan
370 16267.09   21452 hatchback
609 32422.76    9185     coupe
266 10777.05   27906 hatchback
> levels(carSubset$Type)
[1] "convertible" "coupe"       "hatchback"   "sedan"       "wagon"      
> simpleMod <- dummyVars(~Mileage + Type,
+                        data = carSubset,
+                        ## Remove the variable name from the
+                        ## column name
+                        levelsOnly = TRUE)
> simpleMod
Dummy Variable Object

Formula: ~Mileage + Type
2 variables, 1 factors
Factor variable names will be removed
A less than full rank encoding is used
> withInteraction <- dummyVars(~Mileage + Type + Mileage:Type,
+                              data = carSubset,
+                              levelsOnly = TRUE)
> withInteraction
Dummy Variable Object

Formula: ~Mileage + Type + Mileage:Type
2 variables, 1 factors
Factor variable names will be removed
A less than full rank encoding is used
> predict(withInteraction, head(carSubset))
    Mileage convertible coupe hatchback sedan wagon Mileage:Typeconvertible
267   10011           0     0         1     0     0                       0
549     636           0     0         0     1     0                       0
763   21492           0     0         0     1     0                       0
370   21452           0     0         1     0     0                       0
609    9185           0     1         0     0     0                       0
266   27906           0     0         1     0     0                       0
    Mileage:Typecoupe Mileage:Typehatchback Mileage:Typesedan Mileage:Typewagon
267                 0                 10011                 0                 0
549                 0                     0               636                 0
763                 0                     0             21492                 0
370                 0                 21452                 0                 0
609              9185                     0                 0                 0
266                 0                 27906                 0                 0

